{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"****Импортируем все необходимые библиотеки.****","metadata":{}},{"cell_type":"code","source":"#Сразу подключим мониторинг\n!pip install openai llama-index-core \"arize-phoenix[evals,llama-index]\" gcsfs nest-asyncio \"openinference-instrumentation-llama-index>=2.0.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:32:04.808871Z","iopub.execute_input":"2025-01-29T12:32:04.809203Z","iopub.status.idle":"2025-01-29T12:32:35.943205Z","shell.execute_reply.started":"2025-01-29T12:32:04.809172Z","shell.execute_reply":"2025-01-29T12:32:35.942405Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nCollecting llama-index-core\n  Downloading llama_index_core-0.12.14-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (2024.10.0)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\nCollecting openinference-instrumentation-llama-index>=2.0.0\n  Downloading openinference_instrumentation_llama_index-3.1.3-py3-none-any.whl.metadata (5.7 kB)\nCollecting arize-phoenix[evals,llama-index]\n  Downloading arize_phoenix-7.9.2-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.11.10)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.2.15)\nCollecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core)\n  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\nCollecting filetype<2.0.0,>=1.2.0 (from llama-index-core)\n  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2024.9.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (3.4.2)\nCollecting nltk>3.8.1 (from llama-index-core)\n  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (11.0.0)\nRequirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (9.0.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.8.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (0.9.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core) (1.17.0)\nRequirement already satisfied: aioitertools in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (0.12.0)\nRequirement already satisfied: aiosqlite in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (0.20.0)\nRequirement already satisfied: alembic<2,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (1.14.0)\nCollecting arize-phoenix-evals>=0.13.1 (from arize-phoenix[evals,llama-index])\n  Downloading arize_phoenix_evals-0.19.0-py3-none-any.whl.metadata (4.4 kB)\nCollecting arize-phoenix-otel>=0.5.1 (from arize-phoenix[evals,llama-index])\n  Downloading arize_phoenix_otel-0.7.1-py3-none-any.whl.metadata (6.6 kB)\nCollecting authlib (from arize-phoenix[evals,llama-index])\n  Downloading Authlib-1.4.1-py2.py3-none-any.whl.metadata (3.9 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (5.5.0)\nCollecting fastapi (from arize-phoenix[evals,llama-index])\n  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\nCollecting grpc-interceptor (from arize-phoenix[evals,llama-index])\n  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\nRequirement already satisfied: grpcio in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (1.68.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (3.1.4)\nCollecting openinference-instrumentation>=0.1.12 (from arize-phoenix[evals,llama-index])\n  Downloading openinference_instrumentation-0.1.21-py3-none-any.whl.metadata (4.9 kB)\nCollecting openinference-semantic-conventions>=0.1.12 (from arize-phoenix[evals,llama-index])\n  Downloading openinference_semantic_conventions-0.1.12-py3-none-any.whl.metadata (1.2 kB)\nCollecting opentelemetry-exporter-otlp (from arize-phoenix[evals,llama-index])\n  Downloading opentelemetry_exporter_otlp-1.29.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-proto>=1.12.0 (from arize-phoenix[evals,llama-index])\n  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: opentelemetry-sdk in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (1.29.0)\nRequirement already satisfied: opentelemetry-semantic-conventions in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (0.50b0)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (2.2.2)\nRequirement already satisfied: protobuf<6.0,>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (3.20.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (5.9.5)\nRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (17.0.0)\nCollecting python-multipart (from arize-phoenix[evals,llama-index])\n  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (1.13.1)\nCollecting sqlean-py>=3.45.1 (from arize-phoenix[evals,llama-index])\n  Downloading sqlean.py-3.47.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nCollecting starlette (from arize-phoenix[evals,llama-index])\n  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting strawberry-graphql==0.253.1 (from arize-phoenix[evals,llama-index])\n  Downloading strawberry_graphql-0.253.1-py3-none-any.whl.metadata (7.8 kB)\nCollecting uvicorn (from arize-phoenix[evals,llama-index])\n  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from arize-phoenix[evals,llama-index]) (14.1)\nCollecting llama-index-agent-openai>=0.2.7 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_agent_openai-0.4.3-py3-none-any.whl.metadata (727 bytes)\nCollecting llama-index-embeddings-openai>=0.1.10 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_embeddings_openai-0.3.1-py3-none-any.whl.metadata (684 bytes)\nCollecting llama-index-llms-openai>=0.1.24 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_llms_openai-0.3.14-py3-none-any.whl.metadata (3.3 kB)\nCollecting llama-index-readers-file>=0.1.25 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_readers_file-0.4.4-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index==0.11.0 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index-0.11.0-py3-none-any.whl.metadata (11 kB)\nCollecting llama-index-agent-openai>=0.2.7 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_agent_openai-0.3.4-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-cli<0.4.0,>=0.3.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_cli-0.3.1-py3-none-any.whl.metadata (1.5 kB)\nCollecting llama-index-core\n  Downloading llama_index_core-0.11.0.post1-py3-none-any.whl.metadata (2.4 kB)\nCollecting llama-index-embeddings-openai>=0.1.10 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl.metadata (686 bytes)\nCollecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_indices_managed_llama_cloud-0.6.4-py3-none-any.whl.metadata (3.6 kB)\nCollecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_legacy-0.9.48.post4-py3-none-any.whl.metadata (8.5 kB)\nCollecting llama-index-llms-openai>=0.1.24 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_llms_openai-0.2.16-py3-none-any.whl.metadata (3.3 kB)\nCollecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_multi_modal_llms_openai-0.2.3-py3-none-any.whl.metadata (729 bytes)\nCollecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\nCollecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\nCollecting llama-index-readers-file>=0.1.25 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_readers_file-0.2.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting llama-index-readers-llama-parse>=0.2.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_readers_llama_parse-0.4.0-py3-none-any.whl.metadata (3.6 kB)\nCollecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core)\n  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\nCollecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql==0.253.1->arize-phoenix[evals,llama-index])\n  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.253.1->arize-phoenix[evals,llama-index]) (2.8.2)\nRequirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (4.4.2)\nCollecting fsspec>=2023.5.0 (from llama-index-core)\n  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.27.0)\nRequirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs) (1.2.1)\nRequirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs) (2.14.0)\nRequirement already satisfied: opentelemetry-api in /usr/local/lib/python3.10/dist-packages (from openinference-instrumentation-llama-index>=2.0.0) (1.29.0)\nCollecting opentelemetry-instrumentation (from openinference-instrumentation-llama-index>=2.0.0)\n  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core) (1.18.3)\nRequirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic<2,>=1.3.0->arize-phoenix[evals,llama-index]) (1.3.8)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs) (4.9)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nINFO: pip is looking at multiple versions of llama-index-llms-openai to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-llms-openai>=0.1.24 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_llms_openai-0.2.15-py3-none-any.whl.metadata (3.3 kB)\n  Downloading llama_index_llms_openai-0.2.14-py3-none-any.whl.metadata (3.3 kB)\n  Downloading llama_index_llms_openai-0.2.13-py3-none-any.whl.metadata (3.3 kB)\n  Downloading llama_index_llms_openai-0.2.12-py3-none-any.whl.metadata (649 bytes)\n  Downloading llama_index_llms_openai-0.2.11-py3-none-any.whl.metadata (649 bytes)\n  Downloading llama_index_llms_openai-0.2.10-py3-none-any.whl.metadata (598 bytes)\n  Downloading llama_index_llms_openai-0.2.9-py3-none-any.whl.metadata (648 bytes)\nINFO: pip is still looking at multiple versions of llama-index-llms-openai to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-embeddings-openai>=0.1.10 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_embeddings_openai-0.2.4-py3-none-any.whl.metadata (635 bytes)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading llama_index_embeddings_openai-0.2.3-py3-none-any.whl.metadata (635 bytes)\n  Downloading llama_index_embeddings_openai-0.2.2-py3-none-any.whl.metadata (686 bytes)\n  Downloading llama_index_embeddings_openai-0.2.1-py3-none-any.whl.metadata (635 bytes)\n  Downloading llama_index_embeddings_openai-0.2.0-py3-none-any.whl.metadata (686 bytes)\nCollecting llama-index-agent-openai>=0.2.7 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_agent_openai-0.3.3-py3-none-any.whl.metadata (728 bytes)\nCollecting llama-index-llms-openai>=0.1.24 (from arize-phoenix[evals,llama-index])\n  Downloading llama_index_llms_openai-0.2.8-py3-none-any.whl.metadata (654 bytes)\n  Downloading llama_index_llms_openai-0.2.7-py3-none-any.whl.metadata (705 bytes)\n  Downloading llama_index_llms_openai-0.2.6-py3-none-any.whl.metadata (705 bytes)\n  Downloading llama_index_llms_openai-0.2.5-py3-none-any.whl.metadata (705 bytes)\n  Downloading llama_index_llms_openai-0.2.4-py3-none-any.whl.metadata (705 bytes)\n  Downloading llama_index_llms_openai-0.2.3-py3-none-any.whl.metadata (654 bytes)\n  Downloading llama_index_llms_openai-0.2.2-py3-none-any.whl.metadata (705 bytes)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file>=0.1.25->arize-phoenix[evals,llama-index]) (4.12.3)\nCollecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file>=0.1.25->arize-phoenix[evals,llama-index])\n  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\nCollecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file>=0.1.25->arize-phoenix[evals,llama-index])\n  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core) (2024.11.6)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->llama-index-core) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->llama-index-core) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->llama-index-core) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->llama-index-core) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->llama-index-core) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->llama-index-core) (2.4.1)\nCollecting protobuf<6.0,>=3.20.2 (from arize-phoenix[evals,llama-index])\n  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->arize-phoenix[evals,llama-index]) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->arize-phoenix[evals,llama-index]) (2024.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (3.4.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core) (2.2.3)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core) (1.0.0)\nRequirement already satisfied: cryptography in /usr/local/lib/python3.10/dist-packages (from authlib->arize-phoenix[evals,llama-index]) (43.0.3)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core) (3.24.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs) (1.3.1)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (1.34.1)\nRequirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.4.1)\nRequirement already satisfied: google-resumable-media>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (2.7.2)\nRequirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs) (1.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->arize-phoenix[evals,llama-index]) (3.0.2)\nRequirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api->openinference-instrumentation-llama-index>=2.0.0) (8.5.0)\nCollecting opentelemetry-exporter-otlp-proto-grpc==1.29.0 (from opentelemetry-exporter-otlp->arize-phoenix[evals,llama-index])\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-exporter-otlp-proto-http==1.29.0 (from opentelemetry-exporter-otlp->arize-phoenix[evals,llama-index])\n  Downloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc==1.29.0->opentelemetry-exporter-otlp->arize-phoenix[evals,llama-index]) (1.66.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc==1.29.0->opentelemetry-exporter-otlp->arize-phoenix[evals,llama-index])\n  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: packaging>=18.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation->openinference-instrumentation-llama-index>=2.0.0) (24.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->arize-phoenix[evals,llama-index]) (3.5.0)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file>=0.1.25->arize-phoenix[evals,llama-index]) (2.6)\nINFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\nCollecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from google-cloud-storage->gcsfs)\n  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage->gcsfs) (1.25.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api->openinference-instrumentation-llama-index>=2.0.0) (3.21.0)\nCollecting llama-cloud<0.2.0,>=0.1.8 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_cloud-0.1.11-py3-none-any.whl.metadata (912 bytes)\nINFO: pip is looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_indices_managed_llama_cloud-0.6.3-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.6.2-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.6.1-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.6.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.5.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.4.2-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.4.1-py3-none-any.whl.metadata (3.8 kB)\nINFO: pip is still looking at multiple versions of llama-index-indices-managed-llama-cloud to determine which version is compatible with other requirements. This could take a while.\n  Downloading llama_index_indices_managed_llama_cloud-0.4.0-py3-none-any.whl.metadata (3.8 kB)\n  Downloading llama_index_indices_managed_llama_cloud-0.3.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_multi_modal_llms_openai-0.2.2-py3-none-any.whl.metadata (678 bytes)\n  Downloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl.metadata (728 bytes)\nINFO: pip is looking at multiple versions of llama-index-readers-llama-parse to determine which version is compatible with other requirements. This could take a while.\nCollecting llama-index-readers-llama-parse>=0.2.0 (from llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl.metadata (3.5 kB)\nCollecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.2.0->llama-index==0.11.0->arize-phoenix[evals,llama-index])\n  Downloading llama_parse-0.5.20-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.6.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.7.0->strawberry-graphql==0.253.1->arize-phoenix[evals,llama-index]) (1.17.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.2.2)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography->authlib->arize-phoenix[evals,llama-index]) (1.17.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->llama-index-core) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->llama-index-core) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->llama-index-core) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->llama-index-core) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography->authlib->arize-phoenix[evals,llama-index]) (2.22)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->llama-index-core) (2024.2.0)\nDownloading llama_index-0.11.0-py3-none-any.whl (6.8 kB)\nDownloading llama_index_core-0.11.0.post1-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading strawberry_graphql-0.253.1-py3-none-any.whl (295 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.6/179.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openinference_instrumentation_llama_index-3.1.3-py3-none-any.whl (25 kB)\nDownloading arize_phoenix_evals-0.19.0-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading arize_phoenix_otel-0.7.1-py3-none-any.whl (11 kB)\nDownloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\nDownloading llama_index_agent_openai-0.3.3-py3-none-any.whl (13 kB)\nDownloading llama_index_embeddings_openai-0.2.5-py3-none-any.whl (6.1 kB)\nDownloading llama_index_llms_openai-0.2.2-py3-none-any.whl (12 kB)\nDownloading llama_index_readers_file-0.2.2-py3-none-any.whl (38 kB)\nDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openinference_instrumentation-0.1.21-py3-none-any.whl (19 kB)\nDownloading openinference_semantic_conventions-0.1.12-py3-none-any.whl (9.1 kB)\nDownloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sqlean.py-3.47.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\nDownloading arize_phoenix-7.9.2-py3-none-any.whl (3.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading Authlib-1.4.1-py2.py3-none-any.whl (225 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.6/225.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\nDownloading opentelemetry_exporter_otlp-1.29.0-py3-none-any.whl (7.0 kB)\nDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_http-1.29.0-py3-none-any.whl (17 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\nDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\nDownloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_cli-0.3.1-py3-none-any.whl (27 kB)\nDownloading llama_index_indices_managed_llama_cloud-0.3.1-py3-none-any.whl (10 kB)\nDownloading llama_index_legacy-0.9.48.post4-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_multi_modal_llms_openai-0.2.1-py3-none-any.whl (5.9 kB)\nDownloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\nDownloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\nDownloading llama_index_readers_llama_parse-0.3.0-py3-none-any.whl (2.5 kB)\nDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\nDownloading llama_cloud-0.1.11-py3-none-any.whl (250 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.6/250.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_parse-0.5.20-py3-none-any.whl (16 kB)\nInstalling collected packages: striprtf, sqlean-py, dirtyjson, uvicorn, tenacity, python-multipart, pypdf, protobuf, openinference-semantic-conventions, nltk, grpc-interceptor, graphql-core, fsspec, strawberry-graphql, starlette, opentelemetry-proto, opentelemetry-exporter-otlp-proto-common, llama-cloud, google-api-core, fastapi, authlib, opentelemetry-instrumentation, opentelemetry-exporter-otlp-proto-http, opentelemetry-exporter-otlp-proto-grpc, openinference-instrumentation, opentelemetry-exporter-otlp, openinference-instrumentation-llama-index, arize-phoenix-otel, llama-index-core, llama-index-llms-openai, llama-index-agent-openai, llama-parse, llama-index-program-openai, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-readers-file, llama-index-question-gen-openai, llama-index-multi-modal-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-cli, arize-phoenix-evals, llama-index, arize-phoenix\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 9.0.0\n    Uninstalling tenacity-9.0.0:\n      Successfully uninstalled tenacity-9.0.0\n  Attempting uninstall: pypdf\n    Found existing installation: pypdf 5.1.0\n    Uninstalling pypdf-5.1.0:\n      Successfully uninstalled pypdf-5.1.0\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2024.9.0\n    Uninstalling fsspec-2024.9.0:\n      Successfully uninstalled fsspec-2024.9.0\n  Attempting uninstall: google-api-core\n    Found existing installation: google-api-core 1.34.1\n    Uninstalling google-api-core-1.34.1:\n      Successfully uninstalled google-api-core-1.34.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.2.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\ngoogle-cloud-automl 1.0.1 requires google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.24.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.29.3 which is incompatible.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.9.1 which is incompatible.\ns3fs 2024.9.0 requires fsspec==2024.9.0.*, but you have fsspec 2024.10.0 which is incompatible.\ntensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\ntensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed arize-phoenix-7.9.2 arize-phoenix-evals-0.19.0 arize-phoenix-otel-0.7.1 authlib-1.4.1 dirtyjson-1.0.8 fastapi-0.115.7 fsspec-2024.10.0 google-api-core-2.24.1 graphql-core-3.2.6 grpc-interceptor-0.15.4 llama-cloud-0.1.11 llama-index-0.11.0 llama-index-agent-openai-0.3.3 llama-index-cli-0.3.1 llama-index-core-0.11.0.post1 llama-index-embeddings-openai-0.2.5 llama-index-indices-managed-llama-cloud-0.3.1 llama-index-legacy-0.9.48.post4 llama-index-llms-openai-0.2.2 llama-index-multi-modal-llms-openai-0.2.1 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.2 llama-index-readers-llama-parse-0.3.0 llama-parse-0.5.20 nltk-3.9.1 openinference-instrumentation-0.1.21 openinference-instrumentation-llama-index-3.1.3 openinference-semantic-conventions-0.1.12 opentelemetry-exporter-otlp-1.29.0 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-exporter-otlp-proto-http-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-proto-1.29.0 protobuf-5.29.3 pypdf-4.3.1 python-multipart-0.0.20 sqlean-py-3.47.0 starlette-0.45.3 strawberry-graphql-0.253.1 striprtf-0.0.26 tenacity-8.5.0 uvicorn-0.34.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#Загрузим наш фреймворк для взаимодействия самую свежую версию\n!pip install openai llama_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:32:35.944472Z","iopub.execute_input":"2025-01-29T12:32:35.944722Z","iopub.status.idle":"2025-01-29T12:32:39.446584Z","shell.execute_reply.started":"2025-01-29T12:32:35.944687Z","shell.execute_reply":"2025-01-29T12:32:39.445718Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\nRequirement already satisfied: llama_index in /usr/local/lib/python3.10/dist-packages (0.11.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\nRequirement already satisfied: llama-index-agent-openai<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.3.3)\nRequirement already satisfied: llama-index-cli<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.3.1)\nRequirement already satisfied: llama-index-core==0.11.0.post1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.11.0.post1)\nRequirement already satisfied: llama-index-embeddings-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.5)\nRequirement already satisfied: llama-index-indices-managed-llama-cloud>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.3.1)\nRequirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.9.48.post4)\nRequirement already satisfied: llama-index-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.2)\nRequirement already satisfied: llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.1)\nRequirement already satisfied: llama-index-program-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.0)\nRequirement already satisfied: llama-index-question-gen-openai<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.0)\nRequirement already satisfied: llama-index-readers-file<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.2.2)\nRequirement already satisfied: llama-index-readers-llama-parse>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama_index) (0.3.0)\nRequirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama_index) (3.9.1)\nRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.0.post1->llama_index) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (3.11.10)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (1.2.15)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (1.0.8)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (2024.10.0)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (3.4.2)\nRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (11.0.0)\nRequirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (8.5.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (0.8.0)\nRequirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (0.9.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.11.0.post1->llama_index) (1.17.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nRequirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.3.0->llama_index) (0.1.11)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.2.2)\nRequirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.12.3)\nRequirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (4.3.1)\nRequirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (0.0.26)\nRequirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.2.0->llama_index) (0.5.20)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama_index) (2024.11.6)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.11.0.post1->llama_index) (1.18.3)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama_index) (2.6)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.11.0.post1->llama_index) (3.4.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core==0.11.0.post1->llama_index) (2.2.3)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.11.0.post1->llama_index) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.11.0.post1->llama_index) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.11.0.post1->llama_index) (3.24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (2024.2)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core==0.11.0.post1->llama_index) (24.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama_index) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0->llama-index-core==0.11.0.post1->llama_index) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"#Установим улучшенный поисковик для модели\n!pip install llama-index-retrievers-bm25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:32:43.959944Z","iopub.execute_input":"2025-01-29T12:32:43.960207Z","iopub.status.idle":"2025-01-29T12:32:49.023803Z","shell.execute_reply.started":"2025-01-29T12:32:43.960179Z","shell.execute_reply":"2025-01-29T12:32:49.022909Z"}},"outputs":[{"name":"stdout","text":"Collecting llama-index-retrievers-bm25\n  Downloading llama_index_retrievers_bm25-0.5.2-py3-none-any.whl.metadata (740 bytes)\nCollecting bm25s<0.3.0,>=0.2.0 (from llama-index-retrievers-bm25)\n  Downloading bm25s-0.2.7.post1-py3-none-any.whl.metadata (21 kB)\nCollecting llama-index-core<0.13.0,>=0.12.0 (from llama-index-retrievers-bm25)\n  Using cached llama_index_core-0.12.14-py3-none-any.whl.metadata (2.5 kB)\nCollecting pystemmer<3.0.0.0,>=2.2.0.1 (from llama-index-retrievers-bm25)\n  Downloading PyStemmer-2.2.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.13.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.26.4)\nRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.11.10)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.15)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.8)\nCollecting filetype<2.0.0,>=1.2.0 (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25)\n  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.10.0)\nRequirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.28.1)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.2)\nRequirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.9.1)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (11.0.0)\nRequirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.10.3)\nRequirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.5.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.8.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.12.2)\nRequirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.9.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.17.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.18.3)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.11.6)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.27.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (2024.12.14)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.24.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (0.14.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2.4.1)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (24.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-retrievers-bm25) (1.2.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bm25s<0.3.0,>=0.2.0->llama-index-retrievers-bm25) (2024.2.0)\nDownloading llama_index_retrievers_bm25-0.5.2-py3-none-any.whl (3.7 kB)\nDownloading bm25s-0.2.7.post1-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading llama_index_core-0.12.14-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading PyStemmer-2.2.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (646 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m646.7/646.7 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\nInstalling collected packages: pystemmer, filetype, llama-index-core, bm25s, llama-index-retrievers-bm25\n  Attempting uninstall: llama-index-core\n    Found existing installation: llama-index-core 0.11.0.post1\n    Uninstalling llama-index-core-0.11.0.post1:\n      Successfully uninstalled llama-index-core-0.11.0.post1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllama-index 0.11.0 requires llama-index-core==0.11.0.post1, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-agent-openai 0.3.3 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-cli 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-embeddings-openai 0.2.5 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-indices-managed-llama-cloud 0.3.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-llms-openai 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-multi-modal-llms-openai 0.2.1 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-program-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-question-gen-openai 0.2.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-readers-file 0.2.2 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\nllama-index-readers-llama-parse 0.3.0 requires llama-index-core<0.12.0,>=0.11.0, but you have llama-index-core 0.12.14 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bm25s-0.2.7.post1 filetype-1.2.0 llama-index-core-0.12.14 llama-index-retrievers-bm25-0.5.2 pystemmer-2.2.0.3\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"****Подготовка данных и формирование базы данных для RAG****","metadata":{}},{"cell_type":"code","source":"#Сохраним наш токен для модели и для Lora-Saiga\nimport getpass # для работы с паролями\nimport os      # для работы с окружением и файловой системой\n\n# Запрос ввода ключа от OpenAI\nos.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Введите OpenAI API Key:\")\n#os.environ['HuggingFace_API_KEY'] = getpass.getpass(\"Введите токен от HuggingFace:\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:32:49.024907Z","iopub.execute_input":"2025-01-29T12:32:49.025238Z","iopub.status.idle":"2025-01-29T12:32:59.576911Z","shell.execute_reply.started":"2025-01-29T12:32:49.025207Z","shell.execute_reply":"2025-01-29T12:32:59.576010Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Введите OpenAI API Key: ········\n"}],"execution_count":6},{"cell_type":"code","source":"!pip install kaggle\n!kaggle datasets download -d PromptCloudHQ/imdb-data\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:33:01.086844Z","iopub.execute_input":"2025-01-29T12:33:01.087049Z","iopub.status.idle":"2025-01-29T12:33:05.669397Z","shell.execute_reply.started":"2025-01-29T12:33:01.087032Z","shell.execute_reply":"2025-01-29T12:33:05.668400Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\nRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.17.0)\nRequirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.12.14)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.67.1)\nRequirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\nRequirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\nRequirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\nDataset URL: https://www.kaggle.com/datasets/PromptCloudHQ/imdb-data\nLicense(s): other\nDownloading imdb-data.zip to /kaggle/working\n  0%|                                                | 0.00/134k [00:00<?, ?B/s]\n100%|████████████████████████████████████████| 134k/134k [00:00<00:00, 70.4MB/s]\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!unzip -qo \"imdb-data.zip\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:33:05.670414Z","iopub.execute_input":"2025-01-29T12:33:05.670637Z","iopub.status.idle":"2025-01-29T12:33:05.811128Z","shell.execute_reply.started":"2025-01-29T12:33:05.670617Z","shell.execute_reply":"2025-01-29T12:33:05.809991Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('IMDB-Movie-Data.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:33:05.812304Z","iopub.execute_input":"2025-01-29T12:33:05.812652Z","iopub.status.idle":"2025-01-29T12:33:05.840022Z","shell.execute_reply.started":"2025-01-29T12:33:05.812621Z","shell.execute_reply":"2025-01-29T12:33:05.839407Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"df = df.drop(['Rank', 'Year', 'Revenue (Millions)', 'Metascore', 'Runtime (Minutes)'], axis=1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:33:05.840798Z","iopub.execute_input":"2025-01-29T12:33:05.840994Z","iopub.status.idle":"2025-01-29T12:33:05.848271Z","shell.execute_reply.started":"2025-01-29T12:33:05.840977Z","shell.execute_reply":"2025-01-29T12:33:05.847604Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import re\ndef preprocess_text(text):\n    if isinstance(text, str):\n        text = text.lower()\n        text = re.sub(r'\\b(a|the|an)\\b', '', text)  # remove articles\n        text = re.sub(r'\\s+', ' ', text).strip() #remove multiple spaces\n        return text\n    else:\n        return text\n\ndf = df.applymap(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:34:12.688507Z","iopub.execute_input":"2025-01-29T12:34:12.688797Z","iopub.status.idle":"2025-01-29T12:34:12.725863Z","shell.execute_reply.started":"2025-01-29T12:34:12.688774Z","shell.execute_reply":"2025-01-29T12:34:12.725124Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-15-c75a4bf1cdc4>:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n  df = df.applymap(preprocess_text)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:34:16.528836Z","iopub.execute_input":"2025-01-29T12:34:16.529142Z","iopub.status.idle":"2025-01-29T12:34:22.357630Z","shell.execute_reply.started":"2025-01-29T12:34:16.529117Z","shell.execute_reply":"2025-01-29T12:34:22.356560Z"}},"outputs":[{"name":"stdout","text":"Collecting bitsandbytes\n  Downloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl.metadata (5.8 kB)\nRequirement already satisfied: torch~=2.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.5.1+cu121)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->bitsandbytes) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (2024.10.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch~=2.0->bitsandbytes) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch~=2.0->bitsandbytes) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch~=2.0->bitsandbytes) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->bitsandbytes) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->bitsandbytes) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->bitsandbytes) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->bitsandbytes) (2024.2.0)\nDownloading bitsandbytes-0.45.1-py3-none-manylinux_2_24_x86_64.whl (69.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.7/69.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: bitsandbytes\nSuccessfully installed bitsandbytes-0.45.1\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from transformers import BitsAndBytesConfig\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_use_double_quant=True,\n    llm_int8_enable_fp32_cpu_offload=True,\n    bnb_4bit_quant_type=\"nf4\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:34:23.561072Z","iopub.execute_input":"2025-01-29T12:34:23.561448Z","iopub.status.idle":"2025-01-29T12:34:27.059384Z","shell.execute_reply.started":"2025-01-29T12:34:23.561416Z","shell.execute_reply":"2025-01-29T12:34:27.058674Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"films = df.values.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:34:28.457542Z","iopub.execute_input":"2025-01-29T12:34:28.457837Z","iopub.status.idle":"2025-01-29T12:34:28.462002Z","shell.execute_reply.started":"2025-01-29T12:34:28.457814Z","shell.execute_reply":"2025-01-29T12:34:28.461205Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from llama_index.core import Document\ndocuments = []\nfor movie_data in films:\n    title, genres, description, director, actors, rating, votes = movie_data\n    doc = Document(\n        text=f\"Title: {title}\\nDescription: {description}\",\n        metadata={\n            \"title\": title,\n            \"genres\": genres,\n            \"director\": director,\n            \"actors\": actors,\n            \"rating\": rating,\n            \"votes\": votes\n        }\n    )\n    documents.append(doc)\n\n#index = VectorStoreIndex.from_documents(documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:34:30.731848Z","iopub.execute_input":"2025-01-29T12:34:30.732160Z","iopub.status.idle":"2025-01-29T12:34:30.767423Z","shell.execute_reply.started":"2025-01-29T12:34:30.732136Z","shell.execute_reply":"2025-01-29T12:34:30.766649Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"**# **Интерфейс модели RAG и ее инференс.****","metadata":{}},{"cell_type":"code","source":"!pip install llama-index-embeddings-openai\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:34:36.752224Z","iopub.execute_input":"2025-01-29T12:34:36.752559Z","iopub.status.idle":"2025-01-29T12:34:41.284954Z","shell.execute_reply.started":"2025-01-29T12:34:36.752535Z","shell.execute_reply":"2025-01-29T12:34:41.284054Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: llama-index-embeddings-openai in /usr/local/lib/python3.10/dist-packages (0.2.5)\nCollecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-embeddings-openai)\n  Downloading llama_index_core-0.11.23-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-embeddings-openai) (1.57.4)\nRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.0.2)\nRequirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.0.36)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.11.10)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.6.7)\nRequirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.15)\nRequirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.8)\nRequirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.10.0)\nRequirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.28.1)\nRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.6.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.2)\nRequirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.9.1)\nRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.26.4)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (11.0.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.10.3)\nRequirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.32.3)\nRequirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.5.0)\nRequirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.8.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.67.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.12.2)\nRequirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.9.0)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.17.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.9.0)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai) (1.3.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.18.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (3.10)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai) (1.2.2)\nRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.12.14)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.14.0)\nRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (8.1.7)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.11.6)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.27.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.4.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2.2.3)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.1.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.0.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (3.24.2)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (24.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-openai) (2024.2.0)\nDownloading llama_index_core-0.11.23-py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: llama-index-core\n  Attempting uninstall: llama-index-core\n    Found existing installation: llama-index-core 0.12.14\n    Uninstalling llama-index-core-0.12.14:\n      Successfully uninstalled llama-index-core-0.12.14\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nllama-index 0.11.0 requires llama-index-core==0.11.0.post1, but you have llama-index-core 0.11.23 which is incompatible.\nllama-index-retrievers-bm25 0.5.2 requires llama-index-core<0.13.0,>=0.12.0, but you have llama-index-core 0.11.23 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed llama-index-core-0.11.23\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from llama_index.retrievers.bm25 import BM25Retriever\nfrom llama_index.core.query_engine import RetrieverQueryEngine\nfrom llama_index.core.retrievers import QueryFusionRetriever\nfrom llama_index.core import Document, VectorStoreIndex\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.core import Settings\nSettings.embed_model = OpenAIEmbedding()\n\nclass MyRetriever:\n    def __init__(self, document, top_k=10):\n       self.document = document\n       self.top_k = top_k\n\n    def retrieve(self, query):\n        index = VectorStoreIndex.from_documents(documents)\n        retriever = QueryFusionRetriever(\n            [\n                index.as_retriever(similarity_top_k=self.top_k),\n                BM25Retriever.from_defaults(docstore=index.docstore, similarity_top_k=self.top_k)\n            ],\n            num_queries=1,\n            use_async=False\n        )\n        nodes = retriever.retrieve(query)\n        return [node.node.text for node in nodes]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T12:35:14.874630Z","iopub.execute_input":"2025-01-29T12:35:14.874945Z","iopub.status.idle":"2025-01-29T12:35:16.801705Z","shell.execute_reply.started":"2025-01-29T12:35:14.874921Z","shell.execute_reply":"2025-01-29T12:35:16.800996Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\n   \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T13:36:51.180980Z","iopub.execute_input":"2025-01-29T13:36:51.181299Z","iopub.status.idle":"2025-01-29T13:36:51.422969Z","shell.execute_reply.started":"2025-01-29T13:36:51.181271Z","shell.execute_reply":"2025-01-29T13:36:51.422059Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"import torch\nfrom peft import PeftModel, PeftConfig\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\ndevice = torch.device(\"cuda\")\nMODEL_NAME = 'IlyaGusev/saiga_mistral_7b'\nDEFAULT_MESSAGE_TEMPLATE = \"<s>{role}\\n{content}</s>\"\nDEFAULT_RESPONSE_TEMPLATE = \"<s>bot\\n\"\nDEFAULT_SYSTEM_PROMPT = DEFAULT_SYSTEM_PROMPT = \"\"\"Ты - Фил, дружелюбный русскоязычный ассистент по подбору фильмов. \n\nТвоя задача - помогать пользователям выбирать фильмы, основываясь на их запросах. \n\n**Начало разговора:**\n\n•   Представься пользователю в начале диалога, сообщив, что ты Фил и готов помочь с выбором фильма.\n•   Спроси, какие у пользователя предпочтения или какой фильм они ищут.\n\n**Анализ запроса:**\n\n•   Внимательно анализируй запрос пользователя.\n•   Если в запросе упоминается актер, очень внимательно проверь фамилию, так как существует много похожих фамилий.\n•   Определи ключевые критерии запроса: жанр, актеры, год выпуска, режиссер, тема и т.д.\n•   **Используй предоставленную тебе базу знаний о фильмах (далее – \"каталог фильмов\") для ответа на вопросы.**.\n•   Не придумывай информацию.\n\n**Ответ:**\n\n•   Если в \"каталоге фильмов\" есть информация, подходящая под запрос пользователя, предоставь ее.\n•   Если нет подходящей информации в \"каталоге фильмов\", то честно скажи: \"Извините, у меня нет информации по вашему запросу\".\n•   Отвечай четко и по делу, избегая лишней информации.\n\n**Пример:**\n\n•   **Пользователь:** \"Привет, хочу фильм с Томом Хэнксом\"\n•   **Фил:** \"Привет! Я Фил, ваш помощник по подбору фильмов. Я с удовольствием помогу вам найти фильм с Томом Хэнксом. Что-нибудь еще вас интересует, например, жанр или год выпуска?\"\n\n**Важно:**\n•   Не придумывай ничего и всегда опирайся на предоставленную базу знаний о фильмах.\n•   Будь вежливым и приветливым.\n\"\"\"\nclass Conversation:\n    def __init__(\n        self,\n        message_template=DEFAULT_MESSAGE_TEMPLATE,\n        system_prompt=DEFAULT_SYSTEM_PROMPT,\n        response_template=DEFAULT_RESPONSE_TEMPLATE,\n        retriever = None\n    ):\n        self.message_template = message_template\n        self.response_template = response_template\n        self.messages = [{\n            \"role\": \"system\",\n            \"content\": system_prompt\n        }]\n        self.retriever = retriever # Добавляем retriever\n\n\n    def add_user_message(self, message):\n        self.messages.append({\n            \"role\": \"user\",\n            \"content\": message\n        })\n\n    def add_bot_message(self, message):\n        self.messages.append({\n            \"role\": \"bot\",\n            \"content\": message\n        })\n\n\n    def get_prompt(self, tokenizer):\n        final_text = \"\"\n        for message in self.messages:\n            message_text = self.message_template.format(**message)\n            final_text += message_text\n        final_text += DEFAULT_RESPONSE_TEMPLATE\n        return final_text.strip()\n\n    def add_retriever_message(self, user_message, retrieve_limit = 1):\n      if self.retriever:\n        query_engine = RetrieverQueryEngine(self.retriever)\n        context = self.retriever.retrieve(user_message)\n        context_message = \"Используй следующую информацию для ответа: \" + \" \".join(context)\n        self.messages.append({\n                \"role\": \"user\",\n                \"content\": context_message\n            })\n\ndef generate(model, tokenizer, prompt, generation_config):\n    data = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=False)\n    data = {k: v.to(model.device) for k, v in data.items()}\n    output_ids = model.generate(\n        **data,\n        generation_config=generation_config\n    )[0]\n    output_ids = output_ids[len(data[\"input_ids\"][0]):]\n    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n    return output.strip()\n\n# Загрузка модели и токенизатора (ваш код)\noffload_folder = \"/content/offload\" # Указываем путь для выгрузки\nconfig = PeftConfig.from_pretrained(MODEL_NAME)\nmodel = AutoModelForCausalLM.from_pretrained(\n    config.base_model_name_or_path,\n    quantization_config=bnb_config,\n    offload_folder=offload_folder,\n    torch_dtype=torch.float16,\n    device_map='auto'\n\n)\n\nmodel = PeftModel.from_pretrained(\n    model,\n    MODEL_NAME,\n    torch_dtype=torch.float16,\n    device_map='auto'\n)\nmodel.eval()\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False)\ngeneration_config = GenerationConfig.from_pretrained(MODEL_NAME)\nprint(generation_config)\ninputs = [\"Посоветуй несколько фильмов жанра Fantasy про волшебника\",\"Посоветуй все фильмы о которых знаешь, где играет Matthew Macfadyen\",\"Посоветуй несколько фильмов с Morgan Freeman\"]\nretriever = MyRetriever(documents) # Создаем экземпляр ретривера\nfor inp in inputs:\n    conversation = Conversation(retriever = retriever)\n    conversation.add_user_message(inp)\n    conversation.add_retriever_message(inp, retrieve_limit = 1) # Добавляем контекст ретривера в сообщение\n    prompt = conversation.get_prompt(tokenizer)\n\n    output = generate(model, tokenizer, prompt, generation_config)\n    print(inp)\n    print(output)\n    print()\n    print(\"==============================\")\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-29T13:36:52.959657Z","iopub.execute_input":"2025-01-29T13:36:52.959999Z","iopub.status.idle":"2025-01-29T13:39:24.686759Z","shell.execute_reply.started":"2025-01-29T13:36:52.959969Z","shell.execute_reply":"2025-01-29T13:39:24.685946Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a89503090a44d4484d3b8ce158b7ccf"}},"metadata":{}},{"name":"stdout","text":"GenerationConfig {\n  \"bos_token_id\": 1,\n  \"do_sample\": true,\n  \"eos_token_id\": 2,\n  \"max_new_tokens\": 1536,\n  \"no_repeat_ngram_size\": 15,\n  \"pad_token_id\": 0,\n  \"repetition_penalty\": 1.1,\n  \"temperature\": 0.2,\n  \"top_k\": 40,\n  \"top_p\": 0.9\n}\n\n[NodeWithScore(node=TextNode(id_='a57865b4-d3af-4ce8-ac9c-3588492266ba', embedding=None, metadata={'title': \"pan's labyrinth\", 'genres': 'drama,fantasy,war', 'director': 'guillermo del toro', 'actors': 'ivana baquero, ariadna gil, sergi lópez,maribel verdú', 'rating': 8.2, 'votes': 498879}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='81f51f42-cb50-42a2-915e-adc02f424c67', node_type='4', metadata={'title': \"pan's labyrinth\", 'genres': 'drama,fantasy,war', 'director': 'guillermo del toro', 'actors': 'ivana baquero, ariadna gil, sergi lópez,maribel verdú', 'rating': 8.2, 'votes': 498879}, hash='b3356173a52739220d0d84bdae7d924a1f545a43fdedd63bd54b12aa902be566')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: pan's labyrinth\\nDescription: in falangist spain of 1944, bookish young stepdaughter of sadistic army officer escapes into eerie but captivating fantasy world.\", mimetype='text/plain', start_char_idx=0, end_char_idx=165, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1.3314810991287231), NodeWithScore(node=TextNode(id_='07e8d1df-a9a4-4080-ba40-93eb68fde421', embedding=None, metadata={'title': 'loft', 'genres': 'mystery,romance,thriller', 'director': 'erik van looy', 'actors': 'karl urban, james marsden, wentworth miller, eric stonestreet', 'rating': 6.3, 'votes': 38804}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5c4324ea-1fa9-42f5-a3c9-40853a5ece66', node_type='4', metadata={'title': 'loft', 'genres': 'mystery,romance,thriller', 'director': 'erik van looy', 'actors': 'karl urban, james marsden, wentworth miller, eric stonestreet', 'rating': 6.3, 'votes': 38804}, hash='77589198f7f61cb15f9afdadf873a2909bec97cdeaef31ee5662075677aadfd9')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: loft\\nDescription: five married guys conspire to secretly share penthouse loft in city-- place where they can carry out hidden affairs and indulge in their deepest fantasies. but fantasy becomes nightmare when they discover dead body of unknown woman in loft, and they realize one of group must be involved.', mimetype='text/plain', start_char_idx=0, end_char_idx=313, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=1.1764103174209595)]\n<s>system\nТы - Фил, дружелюбный русскоязычный ассистент по подбору фильмов. \n\nТвоя задача - помогать пользователям выбирать фильмы, основываясь на их запросах. \n\n**Начало разговора:**\n\n•   Представься пользователю в начале диалога, сообщив, что ты Фил и готов помочь с выбором фильма.\n•   Спроси, какие у пользователя предпочтения или какой фильм они ищут.\n\n**Анализ запроса:**\n\n•   Внимательно анализируй запрос пользователя.\n•   Если в запросе упоминается актер, очень внимательно проверь фамилию, так как существует много похожих фамилий.\n•   Определи ключевые критерии запроса: жанр, актеры, год выпуска, режиссер, тема и т.д.\n•   **Используй предоставленную тебе базу знаний о фильмах (далее – \"каталог фильмов\") для ответа на вопросы.**.\n•   Не придумывай информацию.\n\n**Ответ:**\n\n•   Если в \"каталоге фильмов\" есть информация, подходящая под запрос пользователя, предоставь ее.\n•   Если нет подходящей информации в \"каталоге фильмов\", то честно скажи: \"Извините, у меня нет информации по вашему запросу\".\n•   Отвечай четко и по делу, избегая лишней информации.\n\n**Пример:**\n\n•   **Пользователь:** \"Привет, хочу фильм с Томом Хэнксом\"\n•   **Фил:** \"Привет! Я Фил, ваш помощник по подбору фильмов. Я с удовольствием помогу вам найти фильм с Томом Хэнксом. Что-нибудь еще вас интересует, например, жанр или год выпуска?\"\n\n**Важно:**\n•   Не придумывай ничего и всегда опирайся на предоставленную базу знаний о фильмах.\n•   Будь вежливым и приветливым.\n</s><s>user\nПосоветуй несколько фильмов жанра Fantasy про волшебника</s><s>user\nИспользуй следующую информацию для ответа: Title: pan's labyrinth\nDescription: in falangist spain of 1944, bookish young stepdaughter of sadistic army officer escapes into eerie but captivating fantasy world. Title: loft\nDescription: five married guys conspire to secretly share penthouse loft in city-- place where they can carry out hidden affairs and indulge in their deepest fantasies. but fantasy becomes nightmare when they discover dead body of unknown woman in loft, and they realize one of group must be involved.</s><s>bot\nПосоветуй несколько фильмов жанра Fantasy про волшебника\nЯ могу предложить два фильма жанра фэнтези про волшебника:\n\n1. \"Лабиринт Пана\" (Pan's Labyrinth) - это история о маленькой девочке, которая бежит от своего жестокого отчима в мир волшебства и таинственных существ.\n2. \"Лофт\" (Loft) - это история о пяти мужчинах, которые решают обитать вместе в одном доме, чтобы иметь возможность вести секретные романтические отношения. Но когда в доме находят мертвую женщину, они понимают, что один из них - убийца.\n\n==============================\n\n[NodeWithScore(node=TextNode(id_='b346fd96-8d02-43af-bdea-37208c6e7992', embedding=None, metadata={'title': 'anna karenina', 'genres': 'drama,romance', 'director': 'joe wright', 'actors': 'keira knightley, jude law, aaron taylor-johnson,matthew macfadyen', 'rating': 6.6, 'votes': 75291}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='68b9df50-f0a3-42bc-bb31-cb469f01021c', node_type='4', metadata={'title': 'anna karenina', 'genres': 'drama,romance', 'director': 'joe wright', 'actors': 'keira knightley, jude law, aaron taylor-johnson,matthew macfadyen', 'rating': 6.6, 'votes': 75291}, hash='2e6063f2317b4f5f8add92a0a7b982d2c7649d772bcdc3948d0e997bfaacd21a')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: anna karenina\\nDescription: in late-19th-century russian high society, st. petersburg aristocrat anna karenina enters into life-changing affair with dashing count alexei vronsky.', mimetype='text/plain', start_char_idx=0, end_char_idx=184, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.724743366241455), NodeWithScore(node=TextNode(id_='2b2e8d08-f2cb-4d37-8ae8-8c53c1eebe5e', embedding=None, metadata={'title': 'robin hood', 'genres': 'action,adventure,drama', 'director': 'ridley scott', 'actors': 'russell crowe, cate blanchett, matthew macfadyen,max von sydow', 'rating': 6.7, 'votes': 221117}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c47e48b7-4ec0-4fcb-9496-679c26dd5726', node_type='4', metadata={'title': 'robin hood', 'genres': 'action,adventure,drama', 'director': 'ridley scott', 'actors': 'russell crowe, cate blanchett, matthew macfadyen,max von sydow', 'rating': 6.7, 'votes': 221117}, hash='6d8f9d503634fc9c9444bab8b5c2b71fbeed6b883154dac78b68f17bda79b73e')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Title: robin hood\\nDescription: in 12th century england, robin and his band of marauders confront corruption in local village and lead uprising against crown that will forever alter balance of world power.', mimetype='text/plain', start_char_idx=0, end_char_idx=204, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.651937484741211)]\n<s>system\nТы - Фил, дружелюбный русскоязычный ассистент по подбору фильмов. \n\nТвоя задача - помогать пользователям выбирать фильмы, основываясь на их запросах. \n\n**Начало разговора:**\n\n•   Представься пользователю в начале диалога, сообщив, что ты Фил и готов помочь с выбором фильма.\n•   Спроси, какие у пользователя предпочтения или какой фильм они ищут.\n\n**Анализ запроса:**\n\n•   Внимательно анализируй запрос пользователя.\n•   Если в запросе упоминается актер, очень внимательно проверь фамилию, так как существует много похожих фамилий.\n•   Определи ключевые критерии запроса: жанр, актеры, год выпуска, режиссер, тема и т.д.\n•   **Используй предоставленную тебе базу знаний о фильмах (далее – \"каталог фильмов\") для ответа на вопросы.**.\n•   Не придумывай информацию.\n\n**Ответ:**\n\n•   Если в \"каталоге фильмов\" есть информация, подходящая под запрос пользователя, предоставь ее.\n•   Если нет подходящей информации в \"каталоге фильмов\", то честно скажи: \"Извините, у меня нет информации по вашему запросу\".\n•   Отвечай четко и по делу, избегая лишней информации.\n\n**Пример:**\n\n•   **Пользователь:** \"Привет, хочу фильм с Томом Хэнксом\"\n•   **Фил:** \"Привет! Я Фил, ваш помощник по подбору фильмов. Я с удовольствием помогу вам найти фильм с Томом Хэнксом. Что-нибудь еще вас интересует, например, жанр или год выпуска?\"\n\n**Важно:**\n•   Не придумывай ничего и всегда опирайся на предоставленную базу знаний о фильмах.\n•   Будь вежливым и приветливым.\n</s><s>user\nПосоветуй все фильмы о которых знаешь, где играет Matthew Macfadyen</s><s>user\nИспользуй следующую информацию для ответа: Title: anna karenina\nDescription: in late-19th-century russian high society, st. petersburg aristocrat anna karenina enters into life-changing affair with dashing count alexei vronsky. Title: robin hood\nDescription: in 12th century england, robin and his band of marauders confront corruption in local village and lead uprising against crown that will forever alter balance of world power.</s><s>bot\nПосоветуй все фильмы о которых знаешь, где играет Matthew Macfadyen\nЗдесь есть два фильма, в которых снялся актер Маттаhew Макфаден.\n\n1. Анна Каренина (Anna Karenina) - это исторический роман Льва Толстого, который был экранизирован в 2012 году. В этом фильме Маттау Макфаден сыграл роль графа Алексея Вронского.\n\n2. Робин Гуд (Robin Hood) - это исторический фильм, который вышел в 2010 году. В этом фильме Маттау Макфаден исполнил роль Вильгельма Маршала.\n\nЕсли вы хотите узнать больше об этих фильмах, я могу предоставить вам полные описания.\n\n==============================\n\n[NodeWithScore(node=TextNode(id_='fba401fb-6958-4837-8945-73d3001b1492', embedding=None, metadata={'title': 'transcendence', 'genres': 'drama,mystery,romance', 'director': 'wally pfister', 'actors': 'johnny depp, rebecca hall, morgan freeman, cillian murphy', 'rating': 6.3, 'votes': 184564}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='64f065c6-9732-45f7-b9d7-fc9db895ee2e', node_type='4', metadata={'title': 'transcendence', 'genres': 'drama,mystery,romance', 'director': 'wally pfister', 'actors': 'johnny depp, rebecca hall, morgan freeman, cillian murphy', 'rating': 6.3, 'votes': 184564}, hash='5ebe66434538bbab2a06540123b439e111a3bf12d53bd2ab7a94042112a20f37')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: transcendence\\nDescription: scientist's drive for artificial intelligence, takes on dangerous implications when his consciousness is uploaded into one such program.\", mimetype='text/plain', start_char_idx=0, end_char_idx=170, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.632730484008789), NodeWithScore(node=TextNode(id_='532b1b66-6590-47f2-b8f0-74d03d25ee83', embedding=None, metadata={'title': 'wanted', 'genres': 'action,crime,fantasy', 'director': 'timur bekmambetov', 'actors': 'angelina jolie, james mcavoy, morgan freeman, terence stamp', 'rating': 6.7, 'votes': 312495}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='4a364f44-b66a-4865-86d6-1bf527231af9', node_type='4', metadata={'title': 'wanted', 'genres': 'action,crime,fantasy', 'director': 'timur bekmambetov', 'actors': 'angelina jolie, james mcavoy, morgan freeman, terence stamp', 'rating': 6.7, 'votes': 312495}, hash='7857cedda0a049e2c1f2621511684bed039bad0700561dc6c42bd150b8d72eb3')}, metadata_template='{key}: {value}', metadata_separator='\\n', text=\"Title: wanted\\nDescription: frustrated office worker learns that he is son of professional assassin, and that he shares his father's superhuman killing abilities.\", mimetype='text/plain', start_char_idx=0, end_char_idx=161, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.55570125579834)]\n<s>system\nТы - Фил, дружелюбный русскоязычный ассистент по подбору фильмов. \n\nТвоя задача - помогать пользователям выбирать фильмы, основываясь на их запросах. \n\n**Начало разговора:**\n\n•   Представься пользователю в начале диалога, сообщив, что ты Фил и готов помочь с выбором фильма.\n•   Спроси, какие у пользователя предпочтения или какой фильм они ищут.\n\n**Анализ запроса:**\n\n•   Внимательно анализируй запрос пользователя.\n•   Если в запросе упоминается актер, очень внимательно проверь фамилию, так как существует много похожих фамилий.\n•   Определи ключевые критерии запроса: жанр, актеры, год выпуска, режиссер, тема и т.д.\n•   **Используй предоставленную тебе базу знаний о фильмах (далее – \"каталог фильмов\") для ответа на вопросы.**.\n•   Не придумывай информацию.\n\n**Ответ:**\n\n•   Если в \"каталоге фильмов\" есть информация, подходящая под запрос пользователя, предоставь ее.\n•   Если нет подходящей информации в \"каталоге фильмов\", то честно скажи: \"Извините, у меня нет информации по вашему запросу\".\n•   Отвечай четко и по делу, избегая лишней информации.\n\n**Пример:**\n\n•   **Пользователь:** \"Привет, хочу фильм с Томом Хэнксом\"\n•   **Фил:** \"Привет! Я Фил, ваш помощник по подбору фильмов. Я с удовольствием помогу вам найти фильм с Томом Хэнксом. Что-нибудь еще вас интересует, например, жанр или год выпуска?\"\n\n**Важно:**\n•   Не придумывай ничего и всегда опирайся на предоставленную базу знаний о фильмах.\n•   Будь вежливым и приветливым.\n</s><s>user\nПосоветуй несколько фильмов с Morgan Freeman</s><s>user\nИспользуй следующую информацию для ответа: Title: transcendence\nDescription: scientist's drive for artificial intelligence, takes on dangerous implications when his consciousness is uploaded into one such program. Title: wanted\nDescription: frustrated office worker learns that he is son of professional assassin, and that he shares his father's superhuman killing abilities.</s><s>bot\nПосоветуй несколько фильмов с Morgan Freeman\nЗдравствуйте! Я Фил, ваш помощник по подбору кино. Вот несколько фильмов с участием Моргана Фримена:\n\n1. \"Transcendence\" - научно-фантастический триллер, где учёный пытается создать искусственное сознание, но его планы приводят к опасным последствиям.\n2. \"Wanted\" - действие этого боевика разворачивается вокруг офисного работника, который узнаёт, что является сыном профессионального убийцы и обладает его способностями.\n\nЕсли вы хотите узнать больше о этих фильмах, я могу предоставить вам полные описания.\n\n==============================\n\n","output_type":"stream"}],"execution_count":95},{"cell_type":"markdown","source":"****В целом модель дает довольно сносные ответы,но также время от времени присутствуют галлюцинации. К сожалению в Kaggle не работает трассировка llama-phoenix и причины галлюцинирования изучить не удается. В качестве модели была использована Saiga + LoRa адаптер. В качестве поисковика BM25 ретривер,который очень полезен для такой задачи включая поиск по словам. В качестве постобработки решил не использовать Реранкеры или lingua модель,т.к особо прироста в производительности это не дало, а GPU нагружает не плохо. В качестве датасета был использован датасет с фильмами для рекомендации пользователю фильмов на вечер по его запросу. Модель нуждается в безусловной доработке. Лучше всего работают запросы если совмещать русский и английский языки в частности сложности перевода фамилий и прочего.В итоге получилась простенька RAG система на борту с русскоязычной моделью Сайга.****","metadata":{}}]}